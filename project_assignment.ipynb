{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "**Initially:**\n",
    "To clean and preprocess a mental health-related Twitter dataset for accurate sentiment analysis in future model development.\n",
    "\n",
    "**Further:**\n",
    "To train a Machine Learning model on the cleaned dataset and make predictions which will be used to evaluate the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID        Topic Sentiment  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "5  2401  Borderlands  Positive   \n",
      "6  2402  Borderlands  Positive   \n",
      "7  2402  Borderlands  Positive   \n",
      "8  2402  Borderlands  Positive   \n",
      "9  2402  Borderlands  Positive   \n",
      "\n",
      "                                       Tweet Content  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "5  im getting into borderlands and i can murder y...  \n",
      "6  So I spent a few hours making something for fu...  \n",
      "7  So I spent a couple of hours doing something f...  \n",
      "8  So I spent a few hours doing something for fun...  \n",
      "9  So I spent a few hours making something for fu...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Our column names were missing at the start\n",
    "\n",
    "column_names = ['ID', 'Topic', 'Sentiment', 'Tweet Content']\n",
    "\n",
    "# assign column names\n",
    "data = pd.read_csv('twitter.csv', names=column_names, header=None)\n",
    "\n",
    "print(data.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Topic', 'Sentiment', 'Tweet Content'], dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "# Data.columns lists the columns in the dataframe, which we set above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                int64\n",
       "Topic            object\n",
       "Sentiment        object\n",
       "Tweet Content    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of objects, which are in this case strings which will need to be processed into something numerical later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6432.586165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3740.427870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID\n",
       "count  74682.000000\n",
       "mean    6432.586165\n",
       "std     3740.427870\n",
       "min        1.000000\n",
       "25%     3195.000000\n",
       "50%     6422.000000\n",
       "75%     9601.000000\n",
       "max    13200.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74682 entries, 0 to 74681\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ID             74682 non-null  int64 \n",
      " 1   Topic          74682 non-null  object\n",
      " 2   Sentiment      74682 non-null  object\n",
      " 3   Tweet Content  73996 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step includes identifying rows containing NAN values, duplicate values, and incorrect sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "rows_with_nan = data[data.isna().any(axis=1)]  # Rows containing NaN \n",
    "\n",
    "duplicate_rows = data[data.duplicated(subset=['Tweet Content'], keep='first')]\n",
    "\n",
    "valid_sentiments = ['positive', 'neutral', 'negative']\n",
    "invalid_sentiments = data[~data['Sentiment'].isin(valid_sentiments)]\n",
    "\n",
    "# Combine all filtered rows \n",
    "filtered = pd.concat([rows_with_nan, duplicate_rows, invalid_sentiments]).drop_duplicates()\n",
    "\n",
    "# removing filtered rows and test\n",
    "data_cleaned = data.drop(filtered.index)\n",
    "\n",
    "print(data_cleaned.isin(filtered).any().any())  # Should hopefully return False \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Tweet Content  \\\n",
      "0  im getting on borderlands and i will murder yo...   \n",
      "1  I am coming to the borders and I will kill you...   \n",
      "2  im getting on borderlands and i will kill you ...   \n",
      "3  im coming on borderlands and i will murder you...   \n",
      "4  im getting on borderlands 2 and i will murder ...   \n",
      "\n",
      "                                       Cleaned Tweet  \n",
      "0   im getting borderlands and i will murder you all  \n",
      "1           i coming borders and i will kill you all  \n",
      "2     im getting borderlands and i will kill you all  \n",
      "3    im coming borderlands and i will murder you all  \n",
      "4  im getting borderlands and i will murder you m...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # Handle non-string inputs and missing values by converting to an empty string\n",
    "    if not isinstance(tweet, str):\n",
    "        tweet = \"\"\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+', '', tweet)\n",
    "    \n",
    "    # Remove mentions (@username)\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    \n",
    "    # Remove hashtags (#hashtag)\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    \n",
    "    # Remove non-alphabetical characters (punctuation, numbers, etc.)\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = {'a', 'an', 'the', 'in', 'on', 'at', 'for', 'to', 'of', 'is', 'are', 'am', 'was', 'were', 'be'}\n",
    "    tweet = ' '.join([word for word in tweet.split() if word not in stop_words])\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "# Apply the function to column\n",
    "data['Cleaned Tweet'] = data['Tweet Content'].apply(clean_tweet)\n",
    "\n",
    "# Check the cleaned tweets\n",
    "print(data[['Tweet Content', 'Cleaned Tweet']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Scatter Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(data['Cleaned Tweet'], data['Sentiment'], alpha=0.5, color='blue')\n",
    "\n",
    "# # Add titles and labels\n",
    "# plt.title('Sentiment Score vs Tweet Content')\n",
    "# plt.xlabel('Tweet')\n",
    "# plt.ylabel('Sentiment Score')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (59745, 34743)\n",
      "Testing data shape: (14937, 34743)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = data[\"Cleaned Tweet\"]  # Features\n",
    "y = data[\"Sentiment\"]      # Labels\n",
    "\n",
    "# T(80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Extraction \n",
    "vectoriser = CountVectorizer()\n",
    "X_train_vec = vectoriser.fit_transform(X_train) \n",
    "X_test_vec = vectoriser.transform(X_test)       \n",
    "\n",
    "# Output shapes for verification\n",
    "print(\"Training data shape:\", X_train_vec.shape)\n",
    "print(\"Testing data shape:\", X_test_vec.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.90\n",
      "Testing Accuracy: 0.80\n",
      "\n",
      "Classification Report (Test Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.85      0.72      0.78      2592\n",
      "    Negative       0.82      0.85      0.83      4519\n",
      "     Neutral       0.82      0.76      0.79      3596\n",
      "    Positive       0.75      0.85      0.80      4230\n",
      "\n",
      "    accuracy                           0.80     14937\n",
      "   macro avg       0.81      0.79      0.80     14937\n",
      "weighted avg       0.81      0.80      0.80     14937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)  # Increased max_iter for convergence\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train_vec)  # Predictions on training data\n",
    "y_test_pred = model.predict(X_test_vec)    # Predictions on test data\n",
    "\n",
    "# Evaluation on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "# Evaluation on test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Test Data):\n",
      "[[1855  232  155  350]\n",
      " [  99 3829  208  383]\n",
      " [ 110  301 2742  443]\n",
      " [ 127  296  225 3582]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Absolutely fantastic service! -> Sentiment: Positive\n",
      "Tweet: I hate how bad this was. -> Sentiment: Negative\n",
      "Tweet: It's neither good nor bad. -> Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Predictions on New Data\n",
    "new_tweets = [\n",
    "    \"Absolutely fantastic service!\", \n",
    "    \"I hate how bad this was.\", \n",
    "    \"It's neither good nor bad.\"\n",
    "]\n",
    "new_tweets_vec = vectoriser.transform(new_tweets)\n",
    "predictions = model.predict(new_tweets_vec)\n",
    "\n",
    "# Output Predictions\n",
    "for tweet, sentiment in zip(new_tweets, predictions):\n",
    "    print(f\"Tweet: {tweet} -> Sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
