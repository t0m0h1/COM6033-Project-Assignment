{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "**Initially:**\n",
    "To clean and preprocess a mental health-related Twitter dataset for accurate sentiment analysis in future model development.\n",
    "\n",
    "**Further:**\n",
    "To train a Machine Learning model on the cleaned dataset and make predictions which will be used to evaluate the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID        Topic Sentiment  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "5  2401  Borderlands  Positive   \n",
      "6  2402  Borderlands  Positive   \n",
      "7  2402  Borderlands  Positive   \n",
      "8  2402  Borderlands  Positive   \n",
      "9  2402  Borderlands  Positive   \n",
      "\n",
      "                                       Tweet Content  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "5  im getting into borderlands and i can murder y...  \n",
      "6  So I spent a few hours making something for fu...  \n",
      "7  So I spent a couple of hours doing something f...  \n",
      "8  So I spent a few hours doing something for fun...  \n",
      "9  So I spent a few hours making something for fu...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Our column names were missing at the start\n",
    "\n",
    "column_names = ['ID', 'Topic', 'Sentiment', 'Tweet Content']\n",
    "\n",
    "# assign column names\n",
    "data = pd.read_csv('twitter.csv', names=column_names, header=None)\n",
    "\n",
    "print(data.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Topic', 'Sentiment', 'Tweet Content'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "# Data.columns lists the columns in the dataframe, which we set above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                int64\n",
       "Topic            object\n",
       "Sentiment        object\n",
       "Tweet Content    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of objects, which are in this case strings which will need to be processed into something numerical later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6432.586165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3740.427870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID\n",
       "count  74682.000000\n",
       "mean    6432.586165\n",
       "std     3740.427870\n",
       "min        1.000000\n",
       "25%     3195.000000\n",
       "50%     6422.000000\n",
       "75%     9601.000000\n",
       "max    13200.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74682 entries, 0 to 74681\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ID             74682 non-null  int64 \n",
      " 1   Topic          74682 non-null  object\n",
      " 2   Sentiment      74682 non-null  object\n",
      " 3   Tweet Content  73996 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step includes identifying rows containing NAN values, duplicate values, and incorrect sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "rows_with_nan = data[data.isna().any(axis=1)]  # Rows containing NaN \n",
    "\n",
    "duplicate_rows = data[data.duplicated(subset=['Tweet Content'], keep='first')]\n",
    "\n",
    "valid_sentiments = ['positive', 'neutral', 'negative']\n",
    "invalid_sentiments = data[~data['Sentiment'].isin(valid_sentiments)]\n",
    "\n",
    "# Combine all filtered rows \n",
    "filtered = pd.concat([rows_with_nan, duplicate_rows, invalid_sentiments]).drop_duplicates()\n",
    "\n",
    "# removing filtered rows and test\n",
    "data_cleaned = data.drop(filtered.index)\n",
    "\n",
    "print(data_cleaned.isin(filtered).any().any())  # Should hopefully return False \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Tweet Content  \\\n",
      "0  im getting on borderlands and i will murder yo...   \n",
      "1  I am coming to the borders and I will kill you...   \n",
      "2  im getting on borderlands and i will kill you ...   \n",
      "3  im coming on borderlands and i will murder you...   \n",
      "4  im getting on borderlands 2 and i will murder ...   \n",
      "\n",
      "                                       Cleaned Tweet  \n",
      "0   im getting borderlands and i will murder you all  \n",
      "1           i coming borders and i will kill you all  \n",
      "2     im getting borderlands and i will kill you all  \n",
      "3    im coming borderlands and i will murder you all  \n",
      "4  im getting borderlands and i will murder you m...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # Handle non-string inputs and missing values by converting to an empty string\n",
    "    if not isinstance(tweet, str):\n",
    "        tweet = \"\"\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+', '', tweet)\n",
    "    \n",
    "    # Remove mentions (@username)\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    \n",
    "    # Remove hashtags (#hashtag)\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    \n",
    "    # Remove non-alphabetical characters (punctuation, numbers, etc.)\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = {'a', 'an', 'the', 'in', 'on', 'at', 'for', 'to', 'of', 'is', 'are', 'am', 'was', 'were', 'be'}\n",
    "    tweet = ' '.join([word for word in tweet.split() if word not in stop_words])\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "# Apply the function to column\n",
    "data['Cleaned Tweet'] = data['Tweet Content'].apply(clean_tweet)\n",
    "\n",
    "# Check the cleaned tweets\n",
    "print(data[['Tweet Content', 'Cleaned Tweet']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Scatter Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(data['Cleaned Tweet'], data['Sentiment'], alpha=0.5, color='blue')\n",
    "\n",
    "# # Add titles and labels\n",
    "# plt.title('Sentiment Score vs Tweet Content')\n",
    "# plt.xlabel('Tweet')\n",
    "# plt.ylabel('Sentiment Score')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sample Data\n",
    "X = data[\"Cleaned Tweet\"]\n",
    "y = data[\"Sentiment\"]  # Labels\n",
    "\n",
    "# Feature Extraction\n",
    "vectoriser = CountVectorizer()\n",
    "X_vec = vectoriser.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Absolutely fantastic service! -> Sentiment: Positive\n",
      "Tweet: I hate how bad this was. -> Sentiment: Negative\n",
      "Tweet: It's neither good nor bad. -> Sentiment: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_vec, y)\n",
    "\n",
    "# Predictions on New Data\n",
    "new_tweets = [\n",
    "    \"Absolutely fantastic service!\", \n",
    "    \"I hate how bad this was.\", \n",
    "    \"It's neither good nor bad.\"\n",
    "]\n",
    "new_tweets_vec = vectoriser.transform(new_tweets)\n",
    "predictions = model.predict(new_tweets_vec)\n",
    "\n",
    "# Output Predictions\n",
    "for tweet, sentiment in zip(new_tweets, predictions):\n",
    "    print(f\"Tweet: {tweet} -> Sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
